{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db5f04ae",
   "metadata": {},
   "source": [
    "# ðŸ§ª Model Experiments Notebook\n",
    "## Build and test your CNN architecture\n",
    "\n",
    "In this notebook, you'll:\n",
    "1. Load your data using PyTorch\n",
    "2. Build your CNN model\n",
    "3. Test the forward pass\n",
    "4. Experiment with different architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d99676",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb25ae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1453e6",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a729a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters - experiment with these!\n",
    "IMAGE_SIZE = 32\n",
    "NUM_CLASSES = 28  # 28 Arabic letters\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 10  # Start small for experiments\n",
    "\n",
    "# Data paths - UPDATE THESE!\n",
    "DATA_DIR = \"../data/raw\"\n",
    "CSV_FILE = \"labels.csv\"  # Adjust to your file name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11447f05",
   "metadata": {},
   "source": [
    "## 3. Build the Dataset Class\n",
    "\n",
    "This is **PILLAR 1** - implement your data loading here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4932e03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArabicLetterDataset(Dataset):\n",
    "    \"\"\"\n",
    "    TODO: Complete this class!\n",
    "\n",
    "    You need to:\n",
    "    1. Load the CSV file in __init__\n",
    "    2. Return the number of samples in __len__\n",
    "    3. Load and return one (image, label) pair in __getitem__\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file: Path to CSV with image paths and labels\n",
    "            root_dir: Directory containing images\n",
    "            transform: Transforms to apply to images\n",
    "        \"\"\"\n",
    "        # TODO: Load CSV file\n",
    "        # self.data_frame = pd.read_csv(csv_file)\n",
    "        # self.root_dir = root_dir\n",
    "        # self.transform = transform\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        # TODO: Return number of samples\n",
    "        # return len(self.data_frame)\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # TODO: Load image and label\n",
    "        # 1. Get image path from CSV\n",
    "        # 2. Load image with PIL\n",
    "        # 3. Apply transforms\n",
    "        # 4. Get label from CSV\n",
    "        # 5. Return (image, label)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bc15ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Scale to [-1, 1]\n",
    "])\n",
    "\n",
    "print(\"Transforms defined:\")\n",
    "print(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1bf7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Uncomment when your Dataset class is complete\n",
    "\n",
    "# # Create dataset\n",
    "# full_dataset = ArabicLetterDataset(\n",
    "#     csv_file=os.path.join(DATA_DIR, CSV_FILE),\n",
    "#     root_dir=DATA_DIR,\n",
    "#     transform=transform\n",
    "# )\n",
    "#\n",
    "# # Split into train and validation\n",
    "# train_size = int(0.8 * len(full_dataset))\n",
    "# val_size = len(full_dataset) - train_size\n",
    "# train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "#     full_dataset, [train_size, val_size]\n",
    "# )\n",
    "#\n",
    "# # Create DataLoaders\n",
    "# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "#\n",
    "# print(f\"Training samples: {len(train_dataset)}\")\n",
    "# print(f\"Validation samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e95909",
   "metadata": {},
   "source": [
    "## 4. Build the CNN Model\n",
    "\n",
    "This is **PILLAR 2** - design your neural network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07adff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArabicCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Network for Arabic Letter Recognition.\n",
    "\n",
    "    Architecture:\n",
    "    - Conv Block 1: Conv2d -> ReLU -> MaxPool\n",
    "    - Conv Block 2: Conv2d -> ReLU -> MaxPool\n",
    "    - Fully Connected: Flatten -> Linear -> ReLU -> Linear\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ArabicCNN, self).__init__()\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        # Pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Fully connected layers\n",
    "        # After 2 pools: 32 -> 16 -> 8, with 64 channels\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, NUM_CLASSES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Conv block 1\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "\n",
    "        # Conv block 2\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded195ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and inspect the model\n",
    "model = ArabicCNN()\n",
    "print(\"Model Architecture:\")\n",
    "print(model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal trainable parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dca4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the forward pass with dummy data\n",
    "dummy_input = torch.randn(1, 1, 32, 32)  # (batch=1, channels=1, height=32, width=32)\n",
    "dummy_output = model(dummy_input)\n",
    "\n",
    "print(f\"Input shape: {dummy_input.shape}\")\n",
    "print(f\"Output shape: {dummy_output.shape}\")\n",
    "print(f\"Expected: (1, {NUM_CLASSES})\")\n",
    "print(f\"\\nâœ“ Forward pass successful!\" if dummy_output.shape == (1, NUM_CLASSES) else \"âœ— Shape mismatch!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764e71e9",
   "metadata": {},
   "source": [
    "## 5. Test Training Loop (Mini Experiment)\n",
    "\n",
    "Let's test that everything works with a small training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef2ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for training\n",
    "model = ArabicCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(f\"Model moved to: {device}\")\n",
    "print(f\"Loss function: CrossEntropyLoss\")\n",
    "print(f\"Optimizer: Adam (lr={LEARNING_RATE})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95188fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with fake data to verify the training loop works\n",
    "print(\"Testing training loop with fake data...\\n\")\n",
    "\n",
    "# Create fake data\n",
    "fake_images = torch.randn(BATCH_SIZE, 1, IMAGE_SIZE, IMAGE_SIZE).to(device)\n",
    "fake_labels = torch.randint(0, NUM_CLASSES, (BATCH_SIZE,)).to(device)\n",
    "\n",
    "# Training step\n",
    "model.train()\n",
    "for epoch in range(3):  # Just 3 fake epochs\n",
    "    # Forward pass\n",
    "    outputs = model(fake_images)\n",
    "    loss = criterion(outputs, fake_labels)\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    accuracy = (predicted == fake_labels).sum().item() / BATCH_SIZE * 100\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Loss = {loss.item():.4f}, Accuracy = {accuracy:.1f}%\")\n",
    "\n",
    "print(\"\\nâœ“ Training loop works!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151a6c98",
   "metadata": {},
   "source": [
    "## 6. Experiment Ideas\n",
    "\n",
    "Once everything works, try these experiments:\n",
    "\n",
    "### A. Change the architecture\n",
    "```python\n",
    "# Try 3 conv layers instead of 2\n",
    "self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "```\n",
    "\n",
    "### B. Add Dropout (reduces overfitting)\n",
    "```python\n",
    "self.dropout = nn.Dropout(0.5)\n",
    "# Use in forward: x = self.dropout(F.relu(self.fc1(x)))\n",
    "```\n",
    "\n",
    "### C. Add Batch Normalization (faster training)\n",
    "```python\n",
    "self.bn1 = nn.BatchNorm2d(32)\n",
    "# Use in forward: x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "```\n",
    "\n",
    "### D. Try different learning rates\n",
    "```python\n",
    "LEARNING_RATE = 0.0001  # Slower but more stable\n",
    "LEARNING_RATE = 0.01    # Faster but might be unstable\n",
    "```\n",
    "\n",
    "### E. Add Data Augmentation\n",
    "```python\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "    # ... rest of transforms\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41fe3ba",
   "metadata": {},
   "source": [
    "## 7. Next Steps\n",
    "\n",
    "Once your experiments work here:\n",
    "\n",
    "1. âœ… Copy working code to `src/dataset.py` and `src/model.py`\n",
    "2. âœ… Implement `src/train.py` with the full training loop\n",
    "3. âœ… Move to `03_final_training.ipynb` for the real training\n",
    "4. âœ… Celebrate your first AI model! ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
