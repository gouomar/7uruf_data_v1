{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df09371d",
   "metadata": {},
   "source": [
    "# üèÜ Final Training Notebook\n",
    "## Train, evaluate, and save your best model\n",
    "\n",
    "This notebook brings everything together for the final training run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f2d3c3",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d922ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Import your modules\n",
    "from config import *\n",
    "from src.utils import set_seed, check_gpu\n",
    "\n",
    "# Setup\n",
    "set_seed()\n",
    "check_gpu()\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b540bf29",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826847e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset functions\n",
    "from src.dataset import ArabicLetterDataset, get_transforms, create_data_loaders\n",
    "\n",
    "# Get transforms\n",
    "transform = get_transforms()\n",
    "\n",
    "# Check if real data exists\n",
    "csv_path = os.path.join('..', DATA_DIR, \"labels.csv\")\n",
    "images_dir = os.path.join('..', DATA_DIR, \"images\")\n",
    "\n",
    "if os.path.exists(csv_path):\n",
    "    # Load real dataset\n",
    "    full_dataset = ArabicLetterDataset(\n",
    "        csv_file=csv_path,\n",
    "        root_dir=images_dir,\n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    # Split into train and validation (80/20)\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        full_dataset, [train_size, val_size]\n",
    "    )\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader, val_loader = create_data_loaders(train_dataset, val_dataset)\n",
    "\n",
    "    print(f\"‚úì Training samples: {len(train_dataset)}\")\n",
    "    print(f\"‚úì Validation samples: {len(val_dataset)}\")\n",
    "else:\n",
    "    # Create dummy data for testing\n",
    "    print(\"‚ö†Ô∏è Real data not found. Creating dummy data for testing...\")\n",
    "\n",
    "    num_train, num_val = 500, 100\n",
    "    train_images = torch.randn(num_train, 1, IMAGE_SIZE, IMAGE_SIZE)\n",
    "    train_labels = torch.randint(0, NUM_CLASSES, (num_train,))\n",
    "    val_images = torch.randn(num_val, 1, IMAGE_SIZE, IMAGE_SIZE)\n",
    "    val_labels = torch.randint(0, NUM_CLASSES, (num_val,))\n",
    "\n",
    "    train_dataset = TensorDataset(train_images, train_labels)\n",
    "    val_dataset = TensorDataset(val_images, val_labels)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    print(f\"‚úì Created {num_train} dummy training samples\")\n",
    "    print(f\"‚úì Created {num_val} dummy validation samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108755ca",
   "metadata": {},
   "source": [
    "## 3. Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bd51db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and create model\n",
    "from src.model import ArabicCNN\n",
    "\n",
    "model = ArabicCNN().to(DEVICE)\n",
    "\n",
    "# Print model info\n",
    "print(f\"Model: ArabicCNN\")\n",
    "print(f\"Input: (1, {IMAGE_SIZE}, {IMAGE_SIZE}) - Grayscale {IMAGE_SIZE}x{IMAGE_SIZE}\")\n",
    "print(f\"Output: {NUM_CLASSES} classes\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24637459",
   "metadata": {},
   "source": [
    "## 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bf5e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "from src.train import train_model\n",
    "\n",
    "history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c247f1e",
   "metadata": {},
   "source": [
    "## 5. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb42ef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "from src.evaluate import plot_training_history\n",
    "\n",
    "plot_training_history(history, save_path='../outputs/training_history.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5941773",
   "metadata": {},
   "source": [
    "## 6. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b91595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from src.evaluate import (\n",
    "    evaluate_model,\n",
    "    plot_confusion_matrix,\n",
    "    get_classification_report,\n",
    "    get_per_class_accuracy\n",
    ")\n",
    "\n",
    "# Get predictions\n",
    "predictions, labels, accuracy = evaluate_model(model, val_loader, DEVICE)\n",
    "\n",
    "# Per-class accuracy\n",
    "get_per_class_accuracy(labels, predictions)\n",
    "\n",
    "# Classification report\n",
    "get_classification_report(labels, predictions, save_path='../outputs/classification_report.txt')\n",
    "\n",
    "# Confusion matrix\n",
    "plot_confusion_matrix(labels, predictions, save_path='../outputs/confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab486aa2",
   "metadata": {},
   "source": [
    "## 7. Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ac4f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "from src.train import save_model\n",
    "\n",
    "save_model(model, '../models/final_model.pth')\n",
    "print(\"‚úì Model saved to models/final_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc7bf59",
   "metadata": {},
   "source": [
    "## 8. Test on Your Own Images!\n",
    "\n",
    "Try writing an Arabic letter and testing it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866b1375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some predictions\n",
    "from src.evaluate import visualize_predictions\n",
    "\n",
    "visualize_predictions(model, val_loader, num_images=16, device=DEVICE, save_path='../outputs/prediction_samples.png')\n",
    "\n",
    "print(\"\\nüéâ Training complete! Check the outputs/ folder for results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6faddc9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üéâ Congratulations!\n",
    "\n",
    "You've built an AI that can recognize handwritten Arabic letters!\n",
    "\n",
    "**What you learned:**\n",
    "- How to load and preprocess image data\n",
    "- How to build a Convolutional Neural Network\n",
    "- How to train a model with PyTorch\n",
    "- How to evaluate model performance\n",
    "\n",
    "**Next challenges:**\n",
    "- Can you get accuracy above 90%?\n",
    "- Try adding more layers or data augmentation\n",
    "- Build a simple web interface to demo your model"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
